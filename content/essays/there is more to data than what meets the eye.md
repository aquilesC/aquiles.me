---
title: There is More to Data than what Meets the Eye
description: Online privacy concerns are rooted in what can be done with user data. However there is little effort in explaining the far reaches of data collection
epistemic: I have been studying the subject for years. I have implemented my own data analysis algorithms and analytics service
status:draft
---
# There is More to Data than what Meets the Eye
When I discuss about online privacy, often I encounter people who simply do not care enough. Their argument is that *data* is only a collection of clicks, of websites visited. The worse thing that can happen is that you see advertisements for the products you are looking for online. What people fail to see is that what they are describing is only the tip of the iceberg of what those clicks and collections of websites can tell about a person. 

One must not forget that the champions for creating public opinion are also the focus of the scrutiny. Facebook, Google, and Amazon are behind most of our interactions online. These corporations have a massive infrastructure to push to the public opinion whatever agenda they want to pursue. There's very little that can be done if they want to cast doubts or fuel misconceptions. 

<blockquote class="quoteback" darkmode="" data-title="AI%20won%E2%80%99t%20relieve%20the%20misery%20of%20Facebook%E2%80%99s%20human%20moderators" data-author="James Vincent" cite="https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms">
When presented with the misery their platforms are creating (as well as other moderation-adjacent problems, like perceived bias) companies often say more technology is the solution. During his hearings in front of congress <a href="https://www.theverge.com/2018/4/11/17226356/mark-zuckerberg-congress-hearing-house-energy-commerce-takeaways" target="_blank" rel="noopener">last year</a>, for example, Zuckerberg cited artificial intelligence more than 30 times as the answer to this and other issues. 
<footer>James Vincent <cite><a href="https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms">https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms</a></cite></footer>
</blockquote>
<script note="" src="https://cdn.jsdelivr.net/gh/Blogger-Peer-Review/quotebacks@1/quoteback.js"></script>

Although social networks can be analyzed from different perspectives, I want to focus on the issue of data collection itself. In this area is not only the super big players involved, but a myriad of small and medium data aggregators distributed around the world. Personal data became a source of revenue and entire business models are created around it. It started as loyalty cards in which we could store rewards, and it morphed into the money that allows us to enjoy some free games on our phones. 

The biggest problem when analyzing the situations is that data itself may be completely innocent: what browser we use, what fonts we have installed on the computer, when did we click on a newsletter article. Every single piece of information, in itself, does not mean anything. 

That is why, the most important thing is to understand [[what is a machine learning algorithm]] and roughly how it works. Maybe there is a correlation between the seemingly *innocent* data and my sexual orientation, or political views. 

From an algorithm perspective, it does not matter whether I explicitly state my political position. The correlation can be found using other's people data and extrapolated to the *innocent* information that was collected from me The two examples of sexual orientation and political inclination are already a problem in today's world. There are countries in which homosexuality can be punished or is highly un-approved by society. In some places political dissent is forbidden. 

But let's not focus solely about "bad actors" such as repressive governments. Imagine we can predict whether a woman is pregnant by looking at her chocolate consumption[^1]. It is reasonable to think that there will be a correlation between chocolate consumption and extended absence at work. If we were a recruiting agency [[Simple explanation of an optimization algorithm|optimizing]] for employee engagement, we wouldn't even need to know the gender of the candidates, we would check the chocolate consumption and [[bias]] our presented candidates towards men that can't get pregnant. 

The example above is highly reductionistic, but it exemplifies what happens also within the most technologically advanced platforms. [Twitter had its racist scandal](https://www.theguardian.com/technology/2020/sep/21/twitter-apologises-for-racist-image-cropping-algorithm), but so did [Google identifying black people as gorillas](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/). And we have no way of knowing how many other examples belong to non-public platforms. And these are only the problems we see *today*.

Data sources are many, and they are for purchase (see: [[Security services buy commercially available private data]]). User data either publicly shared (such as this article), or passively collected (such as [[What can a newsletter know about you|clicks on a newsletter]]) is not going anywhere, it is being accumulated and aggregated without interruptions. The same data that today seems meaningless, tomorrow can be a predictor of behavior the political power of the time does not consider correct. 

Data that today is not aggregated because it belongs to different companies, can be merged easily. Facebook acquired Whatsapp and after some time both databases were merged. Just by checking [[Substack privacy policy]] you can see that they contemplate the idea of selling user data as "an asset", and we have no way of knowing whether they are already doing it, whether our clicks, times to check e-mail, locations, etc. are already in the hands of other aggregators. 

Therefore, when I talk about [[user privacy online]], I am not only thinking about the consequences [[massive data collection]] already has today. I am also concerned about the consequences it will have in the future. We can't guarantee that the freedoms we have today will be the same tomorrow. And we can't know what will be possible to extract from the data we already generated, even if we go completely off-grid from now on. 

There are some individual actions that can create [[a healthier internet]], such as acknowledging [[the power of web developers]]. However, the only path to change is to generate a collective consciousness of the problems that are arising, and understanding that [[the people who is part of the problem cannot be the solution]]. 

<blockquote class="quoteback" darkmode="" data-title="The%20last%20tracker%20was%20just%20removed%20from%20Basecamp.com" data-author="@37svn" cite="https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/">
The internet needs to know less about us, not more. Just because it’s possible to track someone doesn’t mean we should.
<footer>@37svn <cite><a href="https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/">https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/</a></cite></footer>
</blockquote>
<script note="" src="https://cdn.jsdelivr.net/gh/Blogger-Peer-Review/quotebacks@1/quoteback.js"></script>


[^1]: https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/
[^2]: https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms