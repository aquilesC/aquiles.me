---
title: There is More to Data than what Meets the Eye
description: Online privacy concerns are rooted in what can be done with user data. However there is little effort in explaining the far reaches of data collection
epistemic: I have been studying the subject for years. I have implemented my own data analysis algorithms and analytics service
status: draft
---
# There is More to Data than what Meets the Eye
I have discussed about privacy and personal data with different people. I have been told over and over again that if personal data is used to show us advertisements then it is not that bad. However, advertisements are the visible aspect of massive accumulation of data for end consumers. Hiring decisions, credit scores, surveillance, they can be based on personal data. The only difference is that we don't see any of that on our daily lives.  

One of the biggest challenges to create awareness is that data analysis and statistics are fields poorly covered in general education. Massive data accumulators like Facebook, Google, or Amazon, hide their operations between curtains of lexical complexity. Even today, programmers have an aura of *smart people* just because digital literacy is lagging behind. The reality is that some problems are complex, but many of them are not, and personal data can be exploited by anyone who shows a bit of creativity. 

The discussion is complex and probably worth of more than few paragraphs. In any case we must always start by something. I want to lay out the foundations of what I consider is personal data, who benefits from accumulating it, and the responsibility that individual and corporate programmers have in the decisions they make. 

## What is personal data
I would argue that *personal* data is any piece of information that can be linked to a person, even if indirectly. For example, we can register the license plates of the cars that pass through a certain spot in the city. License plates by themselves are not personal information, they belong to a car. However, cars are registered to people. Assuming that the owner of the car was driving it will be a correct assumption in most cases. 

The examples in the online world are very similar. When we surf the internet, we get assigned a unique number called IP address. And the IP address is public in every online interaction, pretty much like a license plate on a car. Every website we visit, every ping a program sends to check whether the license is valid will be associated with an IP address. Assuming that one IP belongs to one person will be correct in a lot of cases. IP addresses *are* personal data, and this is also established by the GDPR regulation in Europe. 

But there is more. Cell phones get unique advertisement identifiers so that companies selling ads can know we are the same person using different apps. I think no one would argue that there is a very intimate link between a phone and a person. Therefore, these ad profiles are as personal as the phone number. The biggest problem is that we don't get to know it, nor change it, nor bring it to a different company. 

Personal data, however, can be obtained also through indirect means. There is a [very interesting paper](https://science.sciencemag.org/content/347/6221/536)[@montjoye2015] showing that once you have enough data, you only need 4 purchases payed for with a credit card to uniquely identify a person. This is, of course, without knowing the credit card number. This information is also known as the **metadata** of a transaction. 

The point of the paper is that even if you have no access to personal information itself you can still identify the person doing the purchases. The same approach works for metadata of communications, e-mails, browsing patterns. Data that is generated by a human action should, in the end, always be treated as personal data, because there is always the possibility of it being *re-identified*, *de-anonymized*, even with methods to which we don't have access today. 

## Where data collection starts
Personal data collection

In this area there are many different actors involved, not only the extremely big players. And all these different companies are scattered around the world, subject to different laws. Since the moment that personal data became a commodity, entire business models were created around it. Perhaps the earliest examples are loyalty cards that allowed us to accumulate points that we could exchange for rewards. The loyalty cards were accumulating data on consumer behavior that could later be fed to consumer analytics models. 

What happens online is not too different from what was happening few decades ago. People are able to release free games online because they get money out of our data. Sometimes it is in the form of an advertisement, sometimes it is by openly sharing all they know of us to many different companies. For example, a weather app I used not only had advertisements it was also sharing my data with other 30 companies

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Something as simple as a weather app (<a href="https://twitter.com/Buienalarm?ref_src=twsrc%5Etfw">@Buienalarm</a>) shares my personal information with about 30 other companies. Seriously? What&#39;s the limit? <a href="https://t.co/cVuB1OXFgN">pic.twitter.com/cVuB1OXFgN</a></p>&mdash; Aquiles Carattino (@aquicarattino) <a href="https://twitter.com/aquicarattino/status/1368493316854194182?ref_src=twsrc%5Etfw">March 7, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

The biggest problem when analyzing the situations is that data itself may be completely innocent: what browser we use, what fonts we have installed on the computer, when did we click on a newsletter article. Every single piece of information, in itself, does not mean anything. 

That is why, the most important thing is to understand [[what is a machine learning algorithm]] and roughly how it works. Maybe there is a correlation between the seemingly *innocent* data and my sexual orientation, or political views. 

From an algorithm perspective, it does not matter whether I explicitly state my political position. The correlation can be found using other's people data and extrapolated to the *innocent* information that was collected from me The two examples of sexual orientation and political inclination are already a problem in today's world. There are countries in which homosexuality can be punished or is highly un-approved by society. In some places political dissent is forbidden. 

But let's not focus solely about "bad actors" such as repressive governments. Imagine we can predict whether a woman is pregnant by looking at her chocolate consumption[^1]. It is reasonable to think that there will be a correlation between chocolate consumption and extended absence at work. If we were a recruiting agency [[Simple explanation of an optimization algorithm|optimizing]] for employee engagement, we wouldn't even need to know the gender of the candidates, we would check the chocolate consumption and [[bias]] our presented candidates towards men that can't get pregnant. 

The example above is highly reductionistic, but it exemplifies what happens also within the most technologically advanced platforms. [Twitter had its racist scandal](https://www.theguardian.com/technology/2020/sep/21/twitter-apologises-for-racist-image-cropping-algorithm), but so did [Google identifying black people as gorillas](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/). And we have no way of knowing how many other examples belong to non-public platforms. And these are only the problems we see *today*.

Data sources are many, and they are for purchase (see: [[Security services buy commercially available private data]]). User data either publicly shared (such as this article), or passively collected (such as [[What can a newsletter know about you|clicks on a newsletter]]) is not going anywhere, it is being accumulated and aggregated without interruptions. The same data that today seems meaningless, tomorrow can be a predictor of behavior the political power of the time does not consider correct. 

Data that today is not aggregated because it belongs to different companies, can be merged easily. Facebook acquired Whatsapp and after some time both databases were merged. Just by checking [[Substack privacy policy]] you can see that they contemplate the idea of selling user data as "an asset", and we have no way of knowing whether they are already doing it, whether our clicks, times to check e-mail, locations, etc. are already in the hands of other aggregators. 

Therefore, when I talk about [[user privacy online]], I am not only thinking about the consequences [[massive data collection]] already has today. I am also concerned about the consequences it will have in the future. We can't guarantee that the freedoms we have today will be the same tomorrow. And we can't know what will be possible to extract from the data we already generated, even if we go completely off-grid from now on. 

There are some individual actions that can create [[a healthier internet]], such as acknowledging [[the power of web developers]]. However, the only path to change is to generate a collective consciousness of the problems that are arising, and understanding that [[the people who is part of the problem cannot be the solution]]. 

<blockquote class="quoteback" darkmode="" data-title="The%20last%20tracker%20was%20just%20removed%20from%20Basecamp.com" data-author="@37svn" cite="https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/">
The internet needs to know less about us, not more. Just because it’s possible to track someone doesn’t mean we should.
<footer>@37svn <cite><a href="https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/">https://m.signalvnoise.com/the-last-tracker-was-just-removed-from-basecamp-com/</a></cite></footer>
</blockquote>
<script note="" src="https://cdn.jsdelivr.net/gh/Blogger-Peer-Review/quotebacks@1/quoteback.js"></script>


[^1]: https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/
[^2]: https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms