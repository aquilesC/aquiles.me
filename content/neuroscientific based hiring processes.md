To screen the adequacy of a candidate for a position/company, looking at the CV is not enough. Therefore it is useful to have tools that can assess personality traits of candidates beyond what is written or what can be explored during an interview. However, some of these tools are based on online assessments techniques that are very poorly validated or that provide very little public information on how they actually work. This leads to immediate concerns about [[gender bias in hiring]] (or any other forms of biases)

For example, **Gild** was an [[artificial intelligence]] tool to hire programmers by screening their online activities. This lead to [[gender biased algorithmic hiring]] because it was using male-focused patterns to judge programming proficiency. 

I got invited to try **Equalture** (https://www.equalture.com/) which proposes unbiased hiring decisions by playing games. However, a quick scan of their website shows that they payed attention to color-blindness and dyslexia, two problems that are either exclusive of men or more predominant on them. 

Perhaps they do achieve an unbiased recruitment process, but there is so little information on their website to justify these claims that I am plainly hesitant about the validity of what they propose. 

Tags: #gender-bias #gender-bias-in-jobs #gender-bias-in-ai 