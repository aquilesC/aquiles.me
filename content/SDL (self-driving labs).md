"[[Self Driving Laboratory]]" is an upcoming trend in new material discovery. Although [[High-throughput]] experimentation has been around for a while, [[biotech]] being a prime example of it, we can move one step forward by closing the loop if we can integrate decision-making to the algorithms driving the experimentation. 

An SDL opens interesting doors when it comes to [[democratizing access to scientific results]]. In principle, a distributed (and interconnected) network of laboratories can be leveraged to perform complex experiments from anywhere in the world (see: [[202504281112 SDL approach to distributed discovery]]). 

It does not preclude the need for [[low-cost experimentation frameworks]], since they will be crucial to developing protocols and new instruments that can be connected to the central facilities. 

There are many challenges still involved in the creation of self-driving laboratories. Some are purely technical and stem from automation and robotics (where most papers focus). Some come from establishing clear interfaces, protocols, data sharing infrastructure, and updating the [[IP regulations for ML discoveries]]. 

People must be trained to work *at* and *with* SDL's. Today, most knowledge institutions work in siloes, where chemistry does not interact with computer science, material science does not work with instrument developers. 

The continuous drop in costs for experimentation may help revisit the approach to teaching the fundamental skills, but at some point there's need for a systematic type of change in the curricula of universities if the goal is to create enough momentum to push forward this new way of working. 

I think there's a great [[overlap between HPC and SDL]], and only when there's true knowledge sharing across disciplines (beyond the purely user-centric one), there'll be a speedup in the deployment of SDL at scale for the next wave of discoveries. 

